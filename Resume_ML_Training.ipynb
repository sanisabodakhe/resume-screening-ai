{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c7ebb7",
   "metadata": {},
   "source": [
    "# Resume Screening System - ML Model Training\n",
    "\n",
    "**Project:** AI Resume Screening System  \n",
    "**Dataset:** 42,106 resumes  \n",
    "**Algorithm:** K-Nearest Neighbors (KNN)  \n",
    "**Goal:** Classify resumes into job categories  \n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates a complete machine learning pipeline:\n",
    "1. Load dataset (42K resumes)\n",
    "2. Preprocess text data\n",
    "3. Extract features using TF-IDF\n",
    "4. Split into training (80%) and test (20%) sets\n",
    "5. Train KNN classifier\n",
    "6. Evaluate model performance\n",
    "7. Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d7cf1",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298381f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn -q\n",
    "print(\"✅ All libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b31d11",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d05b2e",
   "metadata": {},
   "source": [
    "## Step 3: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the resume dataset\n",
    "df = pd.read_csv('src/dataset/UpdatedResumeDataSet.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1baf5fa",
   "metadata": {},
   "source": [
    "## Step 4: Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check unique categories\n",
    "print(f\"\\nNumber of unique job categories: {df['Category'].nunique()}\")\n",
    "\n",
    "# Show category distribution\n",
    "print(\"\\nTop 10 job categories:\")\n",
    "print(df['Category'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681fc0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize category distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['Category'].value_counts().head(15).plot(kind='barh')\n",
    "plt.xlabel('Number of Resumes')\n",
    "plt.ylabel('Job Category')\n",
    "plt.title('Top 15 Job Categories in Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a15f15",
   "metadata": {},
   "source": [
    "## Step 5: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c53323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "df_clean = df.dropna()\n",
    "print(f\"Dataset after removing nulls: {df_clean.shape}\")\n",
    "\n",
    "# Prepare features and labels\n",
    "X = df_clean['Resume'].values\n",
    "y = df_clean['Category'].values\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Labels (y) shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dff611",
   "metadata": {},
   "source": [
    "## Step 6: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Maintains class distribution\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set size: {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea7df6",
   "metadata": {},
   "source": [
    "## Step 7: Feature Extraction - TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,      # Use top 5000 words\n",
    "    min_df=2,               # Min document frequency\n",
    "    max_df=0.8,             # Max document frequency\n",
    "    ngram_range=(1, 2),     # Use unigrams and bigrams\n",
    "    stop_words='english'    # Remove common English words\n",
    ")\n",
    "\n",
    "# Fit on training data and transform both train and test\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vectorizer.get_feature_names_out())}\")\n",
    "print(f\"Training matrix shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Test matrix shape: {X_test_tfidf.shape}\")\n",
    "print(f\"\\nSample features (words): {vectorizer.get_feature_names_out()[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b85389",
   "metadata": {},
   "source": [
    "## Step 8: Train KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0068d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN classifier\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    metric='cosine',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training KNN classifier...\")\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd33b1",
   "metadata": {},
   "source": [
    "## Step 9: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc20ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = knn.predict(X_test_tfidf)\n",
    "print(f\"✅ Predictions made on {len(y_pred)} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73762201",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9de655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21292a3",
   "metadata": {},
   "source": [
    "## Step 11: Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d807b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nDETAILED CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc35b6",
   "metadata": {},
   "source": [
    "## Step 12: Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "print(\"\\nSAMPLE PREDICTIONS (First 20 test samples):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Actual Category':<30} {'Predicted':<30} {'Match'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i in range(min(20, len(y_test))):\n",
    "    actual = y_test[i]\n",
    "    predicted = y_pred[i]\n",
    "    match = \"✅\" if actual == predicted else \"❌\"\n",
    "    print(f\"{actual:<30} {predicted:<30} {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60fa72",
   "metadata": {},
   "source": [
    "## Step 13: Prediction on New Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict category for a new resume\n",
    "new_resume = \"\"\"\n",
    "Java Developer with 5 years experience.\n",
    "Skills: Java, Spring Boot, Hibernate, Maven, JUnit, REST API, Microservices\n",
    "Education: B.Tech in Computer Science\n",
    "Experience: Developed enterprise applications using Spring framework\n",
    "\"\"\"\n",
    "\n",
    "# Vectorize the new resume\n",
    "new_resume_tfidf = vectorizer.transform([new_resume])\n",
    "\n",
    "# Get prediction\n",
    "predicted_category = knn.predict(new_resume_tfidf)[0]\n",
    "\n",
    "print(\"New Resume:\")\n",
    "print(new_resume)\n",
    "print(f\"\\n✅ Predicted Category: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c487d211",
   "metadata": {},
   "source": [
    "## Step 14: Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "summary = {\n",
    "    'Dataset': {\n",
    "        'Total Resumes': len(df_clean),\n",
    "        'Training Samples': len(X_train),\n",
    "        'Test Samples': len(X_test),\n",
    "        'Job Categories': df_clean['Category'].nunique()\n",
    "    },\n",
    "    'Feature Extraction': {\n",
    "        'Method': 'TF-IDF',\n",
    "        'Max Features': 5000,\n",
    "        'N-gram Range': '(1, 2)',\n",
    "        'Stop Words': 'English'\n",
    "    },\n",
    "    'Model': {\n",
    "        'Algorithm': 'K-Nearest Neighbors',\n",
    "        'K Neighbors': 5,\n",
    "        'Distance Metric': 'Cosine'\n",
    "    },\n",
    "    'Performance': {\n",
    "        'Accuracy': f\"{accuracy*100:.2f}%\",\n",
    "        'Precision': f\"{precision*100:.2f}%\",\n",
    "        'Recall': f\"{recall*100:.2f}%\",\n",
    "        'F1 Score': f\"{f1:.4f}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for section, metrics in summary.items():\n",
    "    print(f\"\\n{section}:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  • {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
